{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a45a2-f228-4e60-b8a3-e25d385b789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import cuda, tensor, nn, optim\n",
    "from torchvision import transforms\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "\n",
    "import datasets.catdog_loader as catdog_loader\n",
    "from ptmodels import bic_pytorch as bp\n",
    "\n",
    "# Use a gpu to train PyTorch networks if you have it.\n",
    "pt_device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f'Using {pt_device}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa830ab0-4f8d-4bc2-a20a-fdc5573907eb",
   "metadata": {},
   "source": [
    "# Project One: Dog and Cat Classifier\n",
    "The goal of this project is to use a kaggle dataset to train a dog and cat classifier.  The data consists of user images.  Because this is binary classification, we can probably get away with not doing one-hot encoding.  \n",
    "\n",
    "Two classifiers will be implemented: one with JaX using flax, and the other with PyTorch.  Model archictures will be the same: a multilayer perceptron with relu activations for the hidden layers, and a sigmoid for the output layer.  The number of layers and nodes per layer will be the same between implementations, but said implementations should be flexible and not hardcode layer or node count. \n",
    "\n",
    "The first thing we need to do is load the data and format it for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844e002-9ab5-4fdb-8f6c-d839af075c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('datasets') / 'kagglecatsanddogs_5340' / 'PetImages'\n",
    "cat_path = data_path / 'Cat'\n",
    "dog_path = data_path / 'Dog'\n",
    "cat_img_names = list(cat_path.glob('*.jpg'))\n",
    "dog_img_names = list(dog_path.glob('*.jpg'))\n",
    "\n",
    "def get_image(fname):\n",
    "    assert Path(fname).is_file()\n",
    "    return np.asarray(io.imread(fname), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb3698e-60b6-46e1-afcb-029330a931d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing get_image\n",
    "cat_test = cat_img_names[1]\n",
    "dog_test = dog_img_names[1]\n",
    "\n",
    "cat_test_img = get_image(cat_test)\n",
    "dog_test_img = get_image(dog_test)\n",
    "\n",
    "plt.imshow(cat_test_img)\n",
    "plt.show()\n",
    "plt.imshow(dog_test_img)\n",
    "plt.show()\n",
    "\n",
    "print(cat_test_img.shape, dog_test_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2b5a8e-f010-4fcd-9ee6-8842b638ad30",
   "metadata": {},
   "source": [
    "We already have an issue here --- the images are different shapes.  \n",
    "To train a multilayer perceptron requires intputs to be the same sized vectors.  To resize the image will require an affine transformation, which preserves parallel lines.  \n",
    "The math is not incredibly complicated, but stable implementations already exist with scikit-image, so we will use that package.  \n",
    "Tensorflow and PyTorch also have modules for handling image prep/augmentation. \n",
    "\n",
    "We could also crop the images to the same size, which is not a bad idea --- it also kind of does some data augmentation that could help the classifier.  \n",
    "If we really wanted to spice things up, we could also rotate/reflect these images to further augment the data set.  Naturally, we'd want the classifier to not overfit to particular orientations of animals, which people taking pictures might bias the network to think!  Let's leave that for another day, though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24c4fa-d7d6-4bc4-a011-a3b2f57eb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_resize(fname, img_size=(128, 128)) -> np.ndarray:\n",
    "    \"\"\" Takes a file and and loads it as an imag with given size. \n",
    "\n",
    "    Args:\n",
    "        fname (str or Path): Path of image file. \n",
    "        img_size (tuple, optional): Image size in pixels. Defaults to (128, 128).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Image as an array. \n",
    "    \"\"\"\n",
    "    assert Path(fname).is_file()\n",
    "\n",
    "    # Some files are corrupt, empty, or otherwise problematic. \n",
    "    try:\n",
    "        raw_img = io.imread(fname)\n",
    "    \n",
    "    except ValueError:\n",
    "        print(f'File {fname} raised ValueError. Skipping and returning None')\n",
    "        return None\n",
    "\n",
    "    return np.asarray(transform.resize(raw_img, img_size, anti_aliasing=True), dtype=float)\n",
    "\n",
    "def strict_flatten(arr, size=None):\n",
    "    \"\"\" Forcefully flattens incoming array. \n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): Array to flatten.\n",
    "        # size (int, optional): Size of flattened array. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Flattened array. \n",
    "    \"\"\"\n",
    "    arr_flat = arr.flatten()\n",
    "    # if size:\n",
    "    #     if arr_flat.shape[0] == size:\n",
    "    #         return arr_flat\n",
    "    \n",
    "    return arr_flat\n",
    "\n",
    "cat_test_img_resize = get_image_resize(cat_test)\n",
    "dog_test_img_resize = get_image_resize(dog_test)\n",
    "\n",
    "plt.imshow(cat_test_img_resize)\n",
    "plt.show()\n",
    "plt.imshow(dog_test_img_resize)\n",
    "plt.show()\n",
    "\n",
    "print(cat_test_img_resize.shape, cat_test_img_resize.shape) # We're in business!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3236bd79-bc2c-4064-857a-e3903747043f",
   "metadata": {},
   "source": [
    "Because this is a multiplayer perceptron, it is easiest to just flatten each image into a 1D vectors $\\mathbf{x}$ of length 128 * 128 * 3. Since we are doing binary classification, we also mark dogs with $y=0$ and cats with $y=1$ to get $(\\mathbf{x},y)$ pairs for training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9aba9-b5b0-447e-bff3-0ca588dae93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot(y, n_class):\n",
    "    \"\"\" One-hot mapping.\n",
    "\n",
    "    Args:\n",
    "        y (List or numpy.ndarray): incoming y values as a 1D iterable.\n",
    "        n_class (int): Class number count. \n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: outgoing one-hot vector. \n",
    "    \"\"\"\n",
    "    y_arr = np.asarray(y)\n",
    "    y_new = np.zeros((len(y), n_class))\n",
    "    y_new[np.arange(len(y)), y_arr.astype(int)] = 1\n",
    "    return y_new.reshape((len(y), n_class, 1))\n",
    "\n",
    "def load_dataset(data_path, size=5000, onehot=False, img_size=(128, 128), include_path=False):\n",
    "    \"\"\" This function first loads AND resizes images into a sample of size 'size', and then \n",
    "\n",
    "    Args:\n",
    "        data_path (str or pathlib.Path): Path containing cat and dog image subdirectories.\n",
    "        size (int, optional): Size of training set, split evenly between cats and dogs. Defaults\n",
    "            to 5000.\n",
    "        onehot (bool, optional): Use one-hot encoding. Defaults to False.\n",
    "        img_size (tuple, optional): Size of the resized image. Defaults to (128, 128).\n",
    "        include_path (bool, optional): Returns image file path with loaded image.  Convenient for \n",
    "            debugging. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    cat_path = data_path / 'Cat'\n",
    "    dog_path = data_path / 'Dog'\n",
    "    \n",
    "    # We will split the cat and dog subsamples to each be half the total data set.\n",
    "    if size:\n",
    "        nc = size // 2\n",
    "        nd = size // 2\n",
    "\n",
    "    # Length of x vector. \n",
    "    nx = img_size[0] * img_size[1] * 3\n",
    "\n",
    "    # Lists of file names.\n",
    "    cat_fname_list = list(cat_path.glob('*.jpg'))\n",
    "    dog_fname_list = list(dog_path.glob('*.jpg'))\n",
    "\n",
    "    # The next logic takes into account some images are not RGB color \n",
    "    # images, or are not 128x128 pixel images.  We still need size // 2 images\n",
    "    # for both cats and dogs. \n",
    "    cat_imgs = []\n",
    "    dog_imgs = []\n",
    "    cat_imgs_name = []\n",
    "    dog_imgs_name = []\n",
    "    cc = 0\n",
    "    cd = 1\n",
    "\n",
    "    # For cats. \n",
    "    while True:\n",
    "        # Grab a random image, resize and load it, and test and see if it is the\n",
    "        # right size. \n",
    "        i_c = np.random.randint(0, len(cat_fname_list))\n",
    "        c_cand = cat_fname_list[i_c]\n",
    "        img = get_image_resize(c_cand, img_size=img_size)\n",
    "\n",
    "        if img is None:\n",
    "            # Get rid of img returning None.  Something is wrong with it. \n",
    "            cat_fname_list.pop(i_c)\n",
    "        \n",
    "        elif np.product(img.shape) == nx:\n",
    "            # If it's the right size, then pop our that image from the list. \n",
    "            # We don't want it randomly selected again. \n",
    "            cat_fname_list.pop(i_c)\n",
    "            cc += 1\n",
    "            cat_imgs.append(img)\n",
    "            cat_imgs_name.append(c_cand)\n",
    " \n",
    "        if cc > nc:\n",
    "            break\n",
    "\n",
    "    # Same as above, but for dogs.\n",
    "    while True:\n",
    "        i_d = np.random.randint(0, len(dog_fname_list))\n",
    "        d_cand = dog_fname_list[i_d]\n",
    "        flat_image = strict_flatten(get_image_resize(d_cand, img_size=img_size), size=nx)\n",
    "\n",
    "        if img is None:\n",
    "            dog_fname_list.pop(i_d)\n",
    "        \n",
    "        if flat_image is not None:\n",
    "            dog_fname_list.pop(i_d)\n",
    "            cd += 1\n",
    "            dog_imgs.append(flat_image)\n",
    "            dog_imgs_name.append(d_cand)\n",
    "\n",
    "        if cd > nd:\n",
    "            break\n",
    "\n",
    "    if onehot:\n",
    "        f = lambda y: get_onehot(y, 2)\n",
    "    else:\n",
    "        f = lambda y: y\n",
    "\n",
    "    if include_path:\n",
    "        cat_imgs_ds = list(zip(cat_imgs_name, cat_imgs, f(np.ones((nc, 1)))))\n",
    "        dog_imgs_ds = list(zip(dog_imgs_name, dog_imgs, f(np.zeros((nd, 1)))))\n",
    "    \n",
    "    else:\n",
    "        cat_imgs_ds = list(zip(cat_imgs, f(np.ones((nc, 1)))))\n",
    "        dog_imgs_ds = list(zip(dog_imgs, f(np.zeros((nd, 1)))))\n",
    "        \n",
    "    return cat_imgs_ds + dog_imgs_ds\n",
    "\n",
    "test_ds = load_dataset(data_path, size=10, onehot=True)\n",
    "print(test_ds[0][1]) # one hot encoding is working if we want it!\n",
    "test_ds[0][0].shape, 128 * 128 * 3 # looks good so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f441c0e",
   "metadata": {},
   "source": [
    "The functionality above so far works, but is becoming increasingly unwieldy.  There are couple criticism to share.  First, `load_dataset` loads all images into memory in an incredibly inefficient way.  Second, the transformations have effectively been split between two points in the workflow, a poor design choice in hindsight.  Specifically, when an image is loaded with `get_image_resize`, we are also transforming the image by resizing it.  This is partly necessary because we cannot chain sequential transformations together in `load_dataset`'s current form. \n",
    "\n",
    "There is another issue.  Right now, we are simultaneously trying to handle bad or incompatible images while loading images into the data set.  This intermixing of two distinct objectives into one function call makes `load_dataset` quite opaque and obtuse.  Instead, we could do a one-time check for bad/incompatible images, and remove them before we even consider how to load the data set. After that, we can think about an improved data set loading procedure. \n",
    "\n",
    "We are going to be moving incompatible, corrupt, or bad images to two new directories: `PetImages/notused_cat` and `PetImages/notused_dog`.  It is good practice to not immediately delete problematic data -- for example, you can always come back to it and see if you can transform incompatible file types to increase your training set if you need to!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are just going to script this workflow since it is a one-time thing. \n",
    "\n",
    "notused_cat_path = data_path / 'notused_cat'\n",
    "notused_dog_path = data_path / 'notused_dog'\n",
    "\n",
    "notused_cat_path.mkdir(exist_ok=True)\n",
    "notused_dog_path.mkdir(exist_ok=True)\n",
    "\n",
    "dont_use_cat = []\n",
    "for f in cat_path.glob('*.jpg'):\n",
    "    try:\n",
    "        # First, we load an image and see if it fails.  If it does,\n",
    "        # then we add it to the don't use list. \n",
    "        arr = io.imread(str(f))\n",
    "\n",
    "        # Also, if there are not three color channels, we also are \n",
    "        # going to move the file. \n",
    "        if arr.shape[-1] != 3:\n",
    "            dont_use_cat.append(f)\n",
    "    \n",
    "    except:\n",
    "        print(f'{f} raised exception when read.  Skipping...')\n",
    "        dont_use_cat.append(f)\n",
    "\n",
    "\n",
    "dont_use_dog = []\n",
    "for f in dog_path.glob('*.jpg'):\n",
    "    try:\n",
    "        # First, we load an image and see if it fails.  If it does,\n",
    "        # then we add it to the don't use list. \n",
    "        arr = io.imread(str(f))\n",
    "\n",
    "        # Also, if there are not three color channels, we also are \n",
    "        # going to move the file. \n",
    "        if arr.shape[-1] != 3:\n",
    "            dont_use_dog.append(f)\n",
    "    \n",
    "    except:\n",
    "        dont_use_dog.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c741d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dont_use_cat), len(dont_use_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92356c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It took a minute to go through all the images.  Now we move them \n",
    "# to the new 'not used' directories. \n",
    "for f in dont_use_cat:\n",
    "    new_path = notused_cat_path / f.name\n",
    "    shutil.copy(f, new_path)\n",
    "    f.unlink() # easy way to remove a file located at the path 'f'. \n",
    "\n",
    "for f in dont_use_dog:\n",
    "    new_path = notused_dog_path / f.name\n",
    "    shutil.copy(f, new_path)\n",
    "    f.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd27a269",
   "metadata": {},
   "source": [
    "We have saved troublesome images to look at later if we are so obliged. Let's come back to loading the data set.  As mentioned, we are running into some design issues in our current implementation. Instead of implementing this functionality nearly from scratch, let's use PyTorch's DataSet and DataLoader classes.  The file `catdog_loader.py` contains a DataSet subclass `CatDogDataSet` which we can use to load up the data set.  We can also use `torchvision.transforms` transformations to chain image transformations together for our input image Tensors and outputs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dbd258",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(catdog_loader)\n",
    "pt_transforms = transforms.Compose([transforms.Resize((128, 128), antialias=False)])\n",
    "\n",
    "data_pt = catdog_loader.CatDogDataSet(\n",
    "    data_path, transform=pt_transforms\n",
    ")\n",
    "\n",
    "# If we want one-hot encoding, we could do this using the 'target_transform' kwarg.  Just make sure \n",
    "# to specify the number of classes for the encoding. A lambda function will work well to do that here. \n",
    "# data_pt = catdog_loader.CatDogDataSet(\n",
    "#     data_path, transform=pt_transforms, target_transform=lambda x: nn.functional.one_hot(x, num_classes=2)\n",
    "# )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfe86cf",
   "metadata": {},
   "source": [
    "Already, we see the advantage of not reinventing the wheel.  PyTorch and torchvision provide powerful tools to pre-process, load, and transform data.  Unless otherwise noted, they are tried modules with robust support.  We will stick with PyTorch IO for the remainder of this notebook. \n",
    "\n",
    "Next, we want to prepare the data set to be fed forward through the networks we will be using.  First, we are going to split the data into random subsamples --- one for training, the other for testing. Again, PyTorch makes this easy by providing an easy way to do this with `torch.utils.data.random_split`.  After that, we are going to prepare the data for network feed forward by using the `DataLoader` class.  It makes it easy to create random batches of specified size from a `DataSet` object (specifically, the `CatDogDataSet` object we wrote).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0b30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = random_split(data_pt, [0.8, 0.2])\n",
    "dataload_train = DataLoader(data_train, batch_size=256, shuffle=True)\n",
    "dataload_valid = DataLoader(data_valid, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922efe1c",
   "metadata": {},
   "source": [
    "We are set to start training some networks.  Let's start with a PyTorch implementation of a single layer linear network with a sigmoid activation function.  This is equivalent to logistics classification.  Any neural network training workflow requires we specify a model, a loss function, and an optimizer.  We'll do that now, along with specifying some hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(bp)\n",
    "# Number of epochs and learning rate for optimizer. \n",
    "n_epochs = 1\n",
    "lr = 0.00005\n",
    "\n",
    "# When instantiating the PyTorch logistic classifier model, we can also tell it to use \n",
    "# the specified device to train.  If you have a GPU, this is an easy way to use it.\n",
    "pt_logistic = bp.Logistic(n_in=128 * 128 * 3)# .to(pt_device)\n",
    "\n",
    "# Since this is a binary classification problem, we use a binary cross entropy loss function. \n",
    "# Note that 'binary_cross_entropy' is a function, so don't add () at the end here!\n",
    "pt_log_loss = nn.functional.binary_cross_entropy_with_logits\n",
    "\n",
    "# The optimizer will always need the model parameters as input.  This makes sense --- \n",
    "# you can't optimize a model without changing the model parameters!\n",
    "pt_log_opt = optim.Adam(pt_logistic.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [x for x in pt_logistic.parameters()]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d500ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.reset_params(pt_logistic)\n",
    "\n",
    "v_loss = bp.train_bic_model(dataload_train, dataload_valid, pt_logistic, pt_log_opt, pt_log_loss, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4582d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [x for x in pt_logistic.parameters()]\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5b267a",
   "metadata": {},
   "source": [
    "We've trained a logistics binary image classifier.  Mathematically, this is a not a sophisticated implementation.  Our model is\n",
    "\n",
    "$z_i = \\sum^{N_{pixels}}_j w_jx_j + b_i$, \n",
    "\n",
    "$y_i = \\frac{1}{1 + \\exp(-z_i)}$\n",
    "\n",
    "where $w_j$ is the $j$-th weight (or node) parameter for the $j$-th pixel $x_j$, and $b_i$ is the bias.  $y_i$ is the predicted label, which should be $1$ for cats or $0$ for dogs with a perfect model.  $z_i$ is the unnormalized probability prediction called the logits. \n",
    "\n",
    "A multilayer perceptron can be thought as layered logistic models before feeding logits into the sigmoid function.  Between each layer, and activation function imparts nonlinearity to the model, allowing for the perceptron model to learn more complex behavior than the logistics model above.  Lets have 128 * 128 * 3 nodes for layer 1, 16 * 16 * 3 nodes for layer 2, and 2 * 2 * 3 for layer 3. That finally layer's logits will then be fed into a sigmoid function to provide prediction probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(bp)\n",
    "# Number of epochs and learning rate for optimizer. \n",
    "n_epochs = 1\n",
    "lr = 0.0005\n",
    "\n",
    "# When instantiating a three-layer perception model.\n",
    "n_layers = (49152, 786, 24) # Each layer will become progressively sparse. \n",
    "pt_perceptron = bp.Perceptron(n_layers=n_layers)# .to(pt_device)\n",
    "\n",
    "# Since this is a binary classification problem, we use a binary cross entropy loss function. \n",
    "# Note that 'binary_cross_entropy' is a function, so don't add () at the end here!\n",
    "pt_perp_loss = nn.functional.binary_cross_entropy_with_logits\n",
    "\n",
    "# The optimizer will always need the model parameters as input.  This makes sense --- \n",
    "# you can't optimize a model without changing the model parameters!\n",
    "pt_perp_opt = optim.Adam(pt_perceptron.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c721dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.reset_params(pt_perceptron)\n",
    "\n",
    "v_loss = bp.train_bic_model(dataload_train, dataload_valid, pt_perceptron, pt_perp_opt, pt_perp_loss, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec23d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import unsqueeze\n",
    "\n",
    "for i in range(15):\n",
    "    test_image, test_label = data_valid.__getitem__(i)\n",
    "    # print(pt_logistic(unsqueeze(test_image, 0)), test_label)\n",
    "    plt.imshow(np.asarray(test_image)[0])\n",
    "    plt.show()\n",
    "    print(unsqueeze(test_image, 0).shape)\n",
    "    print(pt_perceptron(unsqueeze(test_image, 0)), test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66828fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
