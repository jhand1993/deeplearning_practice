{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import cuda, tensor, nn, optim\n",
    "from torch.backends import mps\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "import datasets.catdog_loader as mnist_loader\n",
    "from ptmodels import vae_pytorch as vp\n",
    "\n",
    "# Use a gpu or M1 chipset to train PyTorch networks if you have it.\n",
    "if cuda.is_available():\n",
    "    pt_device = 'cuda'\n",
    "\n",
    "elif mps.is_available():\n",
    "    pt_device = 'mps'\n",
    "\n",
    "else: \n",
    "    pt_device = 'cpu'\n",
    "\n",
    "print(f'Using {pt_device}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Autoencoders and Variational Autoencoders.\n",
    "In this project, we are going to first implement a couple autoencoders trained on MNIST-compatible data sets for dimensionality reduction. Afterwards, we'll then create a generative model using a variational autoencoder. \n",
    "\n",
    "## Project 2.1: Autoencoders for Dimensionality Reduction.\n",
    "High dimensionality data frequently has more dimensions than is needed to perform regression, classification, or clustering.  More formally, there is a lot of covariance within most data, covariance that reduces the intrinsic dimensionality of the data set.  Think of image data --- a $128 \\times 128$ pixel image can be thought of as a vector $\\mathbf{x}$ which resides in a 416384$-dimensional vector space. That does not mean there are $16384$ unique features.  Intuitively, we know there are less features in the data, and those features are captured by correlations between pixels.  In other words, we could find a mapping from the starting representation $\\mathbf{x}$ to a reduced-dimension latent representation $\\mathbf{z}\\in \\mathcal{R}^m$, where hopefully $m \\ll 16384$.  We can then use more approachable latent representation $\\mathbf{z}\\in \\mathcal{Z}$ to analyze the starting dataset $\\mathbf{x}\\in \\mathcal{X}$.\n",
    "\n",
    "An autoencoder does this by finding three things: a latent representation $\\mathbf{z}\\in \\mathcal{Z}$, an encoding function $E_{\\phi}(\\mathbf{x})=\\mathbf{z}$ parameterized by $\\phi$, and a decoding function $D_{\\theta}(\\mathbf{z})=\\mathbf{x}$ parameterized by $\\theta$. Here, we will simultaneously train two dense, multi-layer perceptrons to estimate functions $E_{\\phi}$ and $D_{\\theta}$, recovering the latent space $\\mathcal{Z}$ in the process. \n",
    "\n",
    "Training the perceptron networks requires a loss function.  Although the data we are training on is labeled, we will not be using them.  Instead, we are going to perform unsupervised learning.  Specifically, we'll are going to optimize by minimizing the 'distance' between the starting vector $\\mathbf{x}$ and its predicted decoding $D_{\\phi}(E_{\\theta}(\\mathbf{x}))$: \n",
    "\n",
    "$L(\\mathcal{X}|\\phi, \\theta)=-\\frac{1}{N}\\sum^N_{i=1}L_2(\\mathbf{x}_i, D_{\\phi}(E_{\\theta}(\\mathbf{x}_i)))$\n",
    "\n",
    "where $N$ is the size of the training data sample $\\mathcal{X}$ and $L_2(\\mathbf{x}, \\mathbf{x}^{\\prime})=|| \\mathbf{x} - \\mathbf{x}^{\\prime} ||^2$ is the L2 loss (basically, the Euclidian distance up to some multiplicative constant). To train, we will minimize $L(\\mathcal{X}|\\phi, \\theta)$ with respect to the parameters $\\phi$ and $\\theta$.\n",
    "\n",
    "Enough math.  Let's start setting up the model to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlpractice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
